functionality:
  name: submission_171079_train
  namespace: joint_embedding_methods

  # metadata for your method
  description: A description for your method.
  authors:
    - name: John Doe
      email: johndoe@youremailprovider.com
      roles: [ author, maintainer ]
      props: { github: johndoe, orcid: "0000-1111-2222-3333" }

  # parameters
  arguments:
    # required inputs
    - name: "--input_mod1"
      type: "file"
      example: "dataset_mod1.h5ad"
      description: Modality 1 dataset.
      required: true
    - name: "--input_mod2"
      type: "file"
      example: "dataset_mod2.h5ad"
      description: Modality 2 dataset.
      required: true
    - name: "--input_explore_mod1"
      type: "file"
      example: "dataset_mod1.h5ad"
      description: Explore version of the modality 1 dataset.
      required: true
    - name: "--input_explore_mod2"
      type: "file"
      example: "dataset_mod2.h5ad"
      description: Explore version of the modality 2 dataset.
      required: true
    - name: "--tf_seed"
      type: "integer"
      default: 46
      description: ...
    - name: "--np_seed"
      type: "integer"
      default: 56
      description: ...
    
    # required outputs
    - name: "--output_pretrain"
      type: "file"
      direction: "output"
      example: "pretrain_model"
      description: Path to the directory containing a pretrained model.
      required: true

  # files your script needs
  resources:
    - type: python_script
      path: script.py
    - path: '../resources/utils.py'

# target platforms
platforms:
  - type: docker
    image: tensorflow/tensorflow:latest-gpu
    run_args: [ "--gpus all" ]
    setup:
      - type: python
        packages:
          - anndata
          - umap-learn
          - scanpy
  - type: nextflow
    labels: [ vhighmem, vhightime, vhighcpu, gpu ]