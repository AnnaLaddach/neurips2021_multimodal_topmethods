functionality:
  name: submission_170936_171079
  namespace: joint_embedding_methods

  # metadata for your method
  description: A description for your method.
  info:
    submission_id: "170936/171079"
    team_name: Amateur
    # project_url: https://github.com/foo/bar
    # publication_doi: 10.1101/0123.45.67.890123
    # publication_url: https://arxiv.org/abs/1234.56789

  authors:
    - name: John Doe
      email: johndoe@youremailprovider.com
      roles: [ author, maintainer ]
      props: { github: johndoe, orcid: "0000-1111-2222-3333" }

  # parameters
  arguments:
    # required inputs
    - name: "--input_mod1"
      type: "file"
      example: "dataset_mod1.h5ad"
      description: Modality 1 dataset.
      required: true
    - name: "--input_mod2"
      type: "file"
      example: "dataset_mod2.h5ad"
      description: Modality 2 dataset.
      required: true
    - name: "--input_pretrain"
      type: "file"
      example: "pretrain_model"
      description: Path to the directory containing a pretrained model.
      required: true
    # required outputs
    - name: "--output"
      type: "file"
      direction: "output"
      example: "output.h5ad"
      description: Data for all cells in mod1 and mod2 embedded to â‰¤100 dimensions.
      required: true

  # files your script needs
  resources:
    - type: python_script
      path: script.py
    - path: '../resources/utils.py'

# target platforms
platforms:
  - type: docker
    image: tensorflow/tensorflow:latest-gpu
    run_args: [ "--gpus all" ]
    setup:
      - type: python
        packages:
          - anndata
          - umap-learn
          - scanpy
  - type: nextflow
    labels: [ vhighmem, vhightime, vhighcpu, gpu ]